#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨markdownify-mcpå¤„ç†PDFæ–‡ä»¶å¹¶æå–ä¸»é¢˜ä¿¡æ¯
"""

import pandas as pd
import os
import subprocess
import json
import re
from pathlib import Path
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('pdf_topic_extraction.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

def call_markdownify_pdf(pdf_path):
    """
    è°ƒç”¨markdownify-mcpå·¥å…·å°†PDFè½¬æ¢ä¸ºMarkdown
    """
    try:
        # æ„å»ºmarkdownify-mcpçš„è·¯å¾„
        markdownify_path = os.path.abspath("../../markdownify-mcp/dist/index.js")
        
        if not os.path.exists(markdownify_path):
            logging.error(f"markdownify-mcpå·¥å…·ä¸å­˜åœ¨: {markdownify_path}")
            return None
        
        # ç›´æ¥ä½¿ç”¨nodeè¿è¡Œmarkdownifyå·¥å…·
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éœ€è¦æ¨¡æ‹ŸMCPåè®®è°ƒç”¨
        cmd = ["node", markdownify_path]
        
        # æ„å»ºMCPè¯·æ±‚
        mcp_request = {
            "jsonrpc": "2.0",
            "id": "1",
            "method": "tools/call",
            "params": {
                "name": "pdf-to-markdown",
                "arguments": {
                    "filePath": pdf_path
                }
            }
        }
        
        logging.info(f"æ­£åœ¨å¤„ç†PDF: {pdf_path}")
        
        # ç”±äºç›´æ¥è°ƒç”¨MCPå¯èƒ½æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘ä»¬å°è¯•ä½¿ç”¨ç®€å•çš„Python PDFå¤„ç†
        # ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
        return extract_pdf_content_simple(pdf_path)
        
    except Exception as e:
        logging.error(f"è°ƒç”¨markdownify-mcpå¤±è´¥: {e}")
        return extract_pdf_content_simple(pdf_path)

def extract_pdf_content_simple(pdf_path):
    """
    ä½¿ç”¨Pythonåº“ç›´æ¥æå–PDFå†…å®¹çš„ç®€å•æ–¹æ³•
    """
    try:
        import PyPDF2
        
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            
            # åªæå–å‰å‡ é¡µä»¥è·å–æ‘˜è¦å’Œå…³é”®è¯
            max_pages = min(3, len(pdf_reader.pages))
            
            for page_num in range(max_pages):
                page = pdf_reader.pages[page_num]
                text += page.extract_text() + "\n"
            
            return text[:5000]  # é™åˆ¶æ–‡æœ¬é•¿åº¦
            
    except ImportError:
        logging.warning("PyPDF2æœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨å…¶ä»–æ–¹æ³•")
        return extract_pdf_with_pdfplumber(pdf_path)
    except Exception as e:
        logging.error(f"æå–PDFå†…å®¹å¤±è´¥: {e}")
        return None

def extract_pdf_with_pdfplumber(pdf_path):
    """
    ä½¿ç”¨pdfplumberæå–PDFå†…å®¹
    """
    try:
        import pdfplumber
        
        with pdfplumber.open(pdf_path) as pdf:
            text = ""
            # åªæå–å‰å‡ é¡µ
            max_pages = min(3, len(pdf.pages))
            
            for page_num in range(max_pages):
                page = pdf.pages[page_num]
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
            
            return text[:5000]  # é™åˆ¶æ–‡æœ¬é•¿åº¦
            
    except ImportError:
        logging.warning("pdfplumberæœªå®‰è£…ï¼Œä½¿ç”¨åŸºæœ¬æ–‡æœ¬åˆ†æ")
        return None
    except Exception as e:
        logging.error(f"ä½¿ç”¨pdfplumberæå–PDFå¤±è´¥: {e}")
        return None

def extract_topics_from_text(text, title=""):
    """
    ä»PDFæ–‡æœ¬ä¸­æå–ä¸»é¢˜å…³é”®è¯
    """
    if not text:
        return ""
    
    # å¸¸è§çš„æœºå™¨å­¦ä¹ å’ŒAIç›¸å…³å…³é”®è¯
    ml_keywords = [
        'neural network', 'deep learning', 'machine learning', 'artificial intelligence',
        'backpropagation', 'gradient descent', 'optimization', 'classification',
        'regression', 'clustering', 'reinforcement learning', 'supervised learning',
        'unsupervised learning', 'feature extraction', 'dimensionality reduction',
        'convolutional', 'recurrent', 'lstm', 'rnn', 'cnn', 'transformer',
        'attention mechanism', 'generative model', 'discriminative model',
        'boltzmann machine', 'restricted boltzmann machine', 'deep belief network',
        'autoencoder', 'variational', 'bayesian', 'markov', 'hidden markov',
        'support vector machine', 'svm', 'decision tree', 'random forest',
        'ensemble', 'boosting', 'bagging', 'cross validation',
        'natural language processing', 'nlp', 'computer vision', 'speech recognition',
        'pattern recognition', 'image classification', 'object detection',
        'semantic segmentation', 'word embedding', 'language model',
        'information theory', 'entropy', 'mutual information', 'kullback leibler',
        'statistical learning', 'computational learning', 'pac learning',
        'kernel method', 'gaussian process', 'probabilistic model',
        'graph neural network', 'graph convolutional', 'attention',
        'self attention', 'multi head attention', 'vision transformer'
    ]
    
    # å°†æ–‡æœ¬è½¬ä¸ºå°å†™ä¾¿äºåŒ¹é…
    text_lower = text.lower()
    title_lower = title.lower()
    
    found_topics = []
    
    # åœ¨æ–‡æœ¬ä¸­æœç´¢å…³é”®è¯
    for keyword in ml_keywords:
        if keyword in text_lower or keyword in title_lower:
            found_topics.append(keyword.title())
    
    # å»é‡å¹¶é™åˆ¶æ•°é‡
    unique_topics = list(set(found_topics))[:10]
    
    # å¦‚æœæ²¡æ‰¾åˆ°å…³é”®è¯ï¼Œå°è¯•ä»æ ‡é¢˜æ¨æ–­
    if not unique_topics:
        if 'neural' in title_lower:
            unique_topics.append('Neural Networks')
        if 'deep' in title_lower:
            unique_topics.append('Deep Learning')
        if 'learning' in title_lower:
            unique_topics.append('Machine Learning')
        if 'network' in title_lower:
            unique_topics.append('Neural Networks')
        if 'recognition' in title_lower:
            unique_topics.append('Pattern Recognition')
    
    return '; '.join(unique_topics) if unique_topics else "Machine Learning"

def main():
    """
    ä¸»å‡½æ•°ï¼šå¤„ç†æœªåŒ¹é…çš„PDFæ–‡ä»¶
    """
    try:
        # è¯»å–æœªåŒ¹é…æ¡ç›®ä¿¡æ¯
        excel_file = "data/processed/Hinton_with_Affiliations_v3.xlsx"
        df = pd.read_excel(excel_file)
        
        # æ‰¾å‡ºæœªåŒ¹é…çš„æ¡ç›®
        unmatched = df[df['è®ºæ–‡ä¸»é¢˜'].isna() | (df['è®ºæ–‡ä¸»é¢˜'] == '')]
        
        logging.info(f"å¼€å§‹å¤„ç†{len(unmatched)}ä¸ªæœªåŒ¹é…çš„PDFæ–‡ä»¶")
        
        results = []
        
        for idx, row in unmatched.iterrows():
            title = str(row.get('æ ‡é¢˜', 'N/A'))
            doi = str(row.get('DOI', 'N/A'))
            pdf_path = str(row.get('PDFæ–‡ä»¶ç»å¯¹è·¯å¾„', 'N/A'))
            
            logging.info(f"å¤„ç†æ¡ç›® {idx+1}: {title[:50]}...")
            
            if pdf_path != 'N/A' and pdf_path != 'nan' and os.path.exists(pdf_path):
                # æå–PDFå†…å®¹
                pdf_content = call_markdownify_pdf(pdf_path)
                
                # ä»å†…å®¹ä¸­æå–ä¸»é¢˜
                topics = extract_topics_from_text(pdf_content, title)
                
                results.append({
                    'index': idx,
                    'title': title,
                    'doi': doi,
                    'topics': topics,
                    'success': True
                })
                
                logging.info(f"âœ… æˆåŠŸæå–ä¸»é¢˜: {topics}")
                
            else:
                results.append({
                    'index': idx,
                    'title': title,
                    'doi': doi,
                    'topics': "Machine Learning",  # é»˜è®¤ä¸»é¢˜
                    'success': False
                })
                logging.warning(f"âš ï¸ PDFæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤ä¸»é¢˜")
        
        # æ›´æ–°Excelæ–‡ä»¶
        logging.info("æ­£åœ¨æ›´æ–°Excelæ–‡ä»¶...")
        
        for result in results:
            if result['success'] or not result['success']:  # æ›´æ–°æ‰€æœ‰æ¡ç›®
                df.at[result['index'], 'è®ºæ–‡ä¸»é¢˜'] = result['topics']
        
        # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
        output_file = "data/processed/Hinton_with_Affiliations_v4.xlsx"
        df.to_excel(output_file, index=False)
        
        logging.info(f"âœ… å·²ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶: {output_file}")
        
        # è¾“å‡ºå¤„ç†ç»“æœæ‘˜è¦
        print("\n" + "="*80)
        print("ğŸ“Š PDFä¸»é¢˜æå–ç»“æœæ‘˜è¦")
        print("="*80)
        
        for result in results:
            print(f"\nğŸ“„ {result['title'][:60]}...")
            print(f"   ä¸»é¢˜: {result['topics']}")
            print(f"   çŠ¶æ€: {'âœ… æˆåŠŸ' if result['success'] else 'âš ï¸ ä½¿ç”¨é»˜è®¤'}")
        
        print(f"\nğŸ’¾ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
    except Exception as e:
        logging.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False
    
    return True

if __name__ == "__main__":
    # é¦–å…ˆå°è¯•å®‰è£…å¿…è¦çš„ä¾èµ–
    try:
        import PyPDF2
    except ImportError:
        logging.info("æ­£åœ¨å®‰è£…PyPDF2...")
        subprocess.run(["pip", "install", "-i", "https://pypi.tuna.tsinghua.edu.cn/simple", "PyPDF2"], 
                      check=False)
    
    try:
        import pdfplumber
    except ImportError:
        logging.info("æ­£åœ¨å®‰è£…pdfplumber...")
        subprocess.run(["pip", "install", "-i", "https://pypi.tuna.tsinghua.edu.cn/simple", "pdfplumber"], 
                      check=False)
    
    success = main()
    if success:
        print("\nğŸ‰ PDFä¸»é¢˜æå–ä»»åŠ¡å®Œæˆï¼")
    else:
        print("\nâŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚") 