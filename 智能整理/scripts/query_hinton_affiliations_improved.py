#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Geoffrey Hintonæœºæ„ä¿¡æ¯æŸ¥è¯¢è„šæœ¬ï¼ˆæ”¹è¿›ç‰ˆï¼‰
åŠŸèƒ½ï¼šä»CSVæ–‡ä»¶ä¸­æå–Geoffrey Hintonçš„è®ºæ–‡ï¼ŒæŸ¥è¯¢OpenAlex APIè·å–æœºæ„ä¿¡æ¯ï¼Œç”ŸæˆExcelæ–‡ä»¶

æ”¹è¿›å†…å®¹ï¼š
1. ä¿®å¤DOIæ ¼å¼é—®é¢˜ï¼ˆä¸‹åˆ’çº¿è½¬æ–œæ ï¼‰
2. ä¼˜åŒ–APIæŸ¥è¯¢é€»è¾‘
3. å¢åŠ è¯¦ç»†é”™è¯¯å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯

ä½œè€…ï¼šAIåŠ©æ‰‹
ç‰ˆæœ¬ï¼š2.0
åˆ›å»ºæ—¶é—´ï¼š2025-01-27
"""

import pandas as pd
import requests
import time
import os
from datetime import datetime
import logging
from pathlib import Path
import re

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('hinton_affiliations_query_improved.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class HintonAffiliationsQueryImproved:
    """Geoffrey Hintonæœºæ„ä¿¡æ¯æŸ¥è¯¢ç±»ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
    
    def __init__(self, csv_file_path, pdf_dir_path):
        """
        åˆå§‹åŒ–æŸ¥è¯¢å™¨
        
        Args:
            csv_file_path (str): è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
            pdf_dir_path (str): PDFæ–‡ä»¶ç›®å½•è·¯å¾„
        """
        self.csv_file_path = csv_file_path
        self.pdf_dir_path = pdf_dir_path
        self.base_url = "https://api.openalex.org/works"
        
        # ç»“æœå­˜å‚¨
        self.results = []
        
    def normalize_doi(self, doi):
        """
        æ ‡å‡†åŒ–DOIæ ¼å¼
        å°†ä¸‹åˆ’çº¿æ ¼å¼çš„DOIè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        
        Args:
            doi (str): åŸå§‹DOIå­—ç¬¦ä¸²
            
        Returns:
            str: æ ‡å‡†åŒ–åçš„DOI
        """
        if not doi:
            return ""
        
        # ç§»é™¤å¯èƒ½çš„å‰ç¼€
        doi = doi.strip()
        if doi.startswith('doi:'):
            doi = doi[4:]
        if doi.startswith('DOI:'):
            doi = doi[4:]
        
        # å°†ä¸‹åˆ’çº¿è½¬æ¢ä¸ºæ–œæ ï¼ˆä½†ä¿ç•™DOIå‰ç¼€åçš„ä¸‹åˆ’çº¿ï¼‰
        # ä¾‹å¦‚ï¼š10.1038_306021a0 -> 10.1038/306021a0
        if '_' in doi and '/' not in doi:
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªä¸‹åˆ’çº¿çš„ä½ç½®
            first_underscore = doi.find('_')
            if first_underscore > 0:
                # å°†ç¬¬ä¸€ä¸ªä¸‹åˆ’çº¿æ›¿æ¢ä¸ºæ–œæ 
                doi = doi[:first_underscore] + '/' + doi[first_underscore+1:]
        
        logger.debug(f"DOIæ ‡å‡†åŒ–: {doi}")
        return doi
    
    def read_csv_data(self):
        """è¯»å–CSVæ–‡ä»¶æ•°æ®"""
        try:
            logger.info(f"æ­£åœ¨è¯»å–CSVæ–‡ä»¶: {self.csv_file_path}")
            df = pd.read_csv(self.csv_file_path, encoding='utf-8')
            logger.info(f"æˆåŠŸè¯»å– {len(df)} æ¡è®°å½•")
            return df
        except Exception as e:
            logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def filter_hinton_papers(self, df):
        """ç­›é€‰Geoffrey Hintonä½œä¸ºä½œè€…çš„è®ºæ–‡"""
        try:
            # ç­›é€‰åŒ…å«Geoffrey Hintonçš„è®ºæ–‡
            hinton_papers = df[df['Author'].str.contains('Hinton, Geoffrey', na=False)]
            logger.info(f"æ‰¾åˆ° {len(hinton_papers)} ç¯‡Geoffrey Hintonçš„è®ºæ–‡")
            
            # æ‰“å°ä¸€äº›è°ƒè¯•ä¿¡æ¯
            for i, (idx, paper) in enumerate(hinton_papers.head(3).iterrows()):
                logger.info(f"æ ·æœ¬è®ºæ–‡ {i+1}: {paper['Title'][:50]}... DOI: {paper['DOI']}")
            
            return hinton_papers
        except Exception as e:
            logger.error(f"ç­›é€‰è®ºæ–‡å¤±è´¥: {e}")
            raise
    
    def query_openalex_by_doi(self, original_doi):
        """
        é€šè¿‡DOIæŸ¥è¯¢OpenAlex APIè·å–æœºæ„ä¿¡æ¯
        
        Args:
            original_doi (str): åŸå§‹DOI
            
        Returns:
            list: Geoffrey Hintonçš„æœºæ„ä¿¡æ¯åˆ—è¡¨
        """
        try:
            # æ ‡å‡†åŒ–DOI
            doi = self.normalize_doi(original_doi)
            
            # å°è¯•å¤šç§æŸ¥è¯¢æ–¹å¼
            query_urls = [
                f"{self.base_url}?filter=doi:{doi}",
                f"{self.base_url}?search={doi}",
                f"{self.base_url}?filter=doi:https://doi.org/{doi}"
            ]
            
            logger.info(f"æ­£åœ¨æŸ¥è¯¢DOI: {original_doi} -> {doi}")
            
            # å‘é€è¯·æ±‚å¤´
            headers = {
                'User-Agent': 'HintonAffiliationsQuery/2.0 (mailto:research@example.com)',
                'Accept': 'application/json'
            }
            
            for i, url in enumerate(query_urls):
                try:
                    logger.debug(f"å°è¯•æŸ¥è¯¢æ–¹æ³• {i+1}: {url}")
                    response = requests.get(url, headers=headers, timeout=15)
                    
                    if response.status_code == 200:
                        data = response.json()
                        
                        if data.get('results'):
                            work = data['results'][0]
                            logger.info(f"æ‰¾åˆ°è®ºæ–‡: {work.get('title', 'Unknown')}")
                            
                            # æŸ¥æ‰¾Geoffrey Hintonçš„æœºæ„ä¿¡æ¯
                            hinton_affiliations = []
                            
                            for authorship in work.get('authorships', []):
                                author = authorship.get('author', {})
                                author_name = author.get('display_name', '')
                                
                                # æ£€æŸ¥æ˜¯å¦ä¸ºGeoffrey Hinton
                                if self.is_hinton_author(author_name):
                                    logger.info(f"æ‰¾åˆ°åŒ¹é…ä½œè€…: {author_name}")
                                    
                                    # æå–æœºæ„ä¿¡æ¯
                                    institutions = authorship.get('institutions', [])
                                    for inst in institutions:
                                        inst_name = inst.get('display_name', 'Unknown Institution')
                                        inst_country = inst.get('country_code', '')
                                        inst_type = inst.get('type', '')
                                        
                                        # æ„å»ºå®Œæ•´çš„æœºæ„ä¿¡æ¯
                                        full_inst_name = inst_name
                                        if inst_country:
                                            full_inst_name += f" ({inst_country})"
                                        if inst_type and inst_type != 'unknown':
                                            full_inst_name += f" [{inst_type}]"
                                        
                                        hinton_affiliations.append(full_inst_name)
                            
                            if hinton_affiliations:
                                logger.info(f"æ‰¾åˆ° {len(hinton_affiliations)} ä¸ªæœºæ„ä¿¡æ¯: {hinton_affiliations}")
                                return hinton_affiliations
                            else:
                                logger.warning(f"åœ¨è®ºæ–‡ä¸­æœªæ‰¾åˆ°Geoffrey Hintonçš„æœºæ„ä¿¡æ¯")
                        else:
                            logger.debug(f"æŸ¥è¯¢æ–¹æ³• {i+1} æœªè¿”å›ç»“æœ")
                    else:
                        logger.debug(f"æŸ¥è¯¢æ–¹æ³• {i+1} è¿”å›çŠ¶æ€ç : {response.status_code}")
                        
                except requests.exceptions.RequestException as e:
                    logger.debug(f"æŸ¥è¯¢æ–¹æ³• {i+1} è¯·æ±‚å¼‚å¸¸: {e}")
                    continue
                
                # é¿å…é¢‘ç¹è¯·æ±‚
                time.sleep(0.5)
            
            logger.warning(f"æ‰€æœ‰æŸ¥è¯¢æ–¹æ³•éƒ½æœªæ‰¾åˆ°DOI {original_doi} çš„ç›¸å…³ä¿¡æ¯")
            return []
                
        except Exception as e:
            logger.error(f"æŸ¥è¯¢DOI {original_doi} æ—¶å‡ºé”™: {e}")
            return []
    
    def is_hinton_author(self, author_name):
        """
        åˆ¤æ–­ä½œè€…æ˜¯å¦ä¸ºGeoffrey Hinton
        
        Args:
            author_name (str): ä½œè€…å§“å
            
        Returns:
            bool: æ˜¯å¦ä¸ºGeoffrey Hinton
        """
        if not author_name:
            return False
        
        author_name_lower = author_name.lower()
        
        # å¤šç§å¯èƒ½çš„å§“åå˜ä½“
        hinton_variants = [
            'geoffrey hinton',
            'geoffrey e. hinton',
            'geoffrey everest hinton',
            'g. hinton',
            'g.e. hinton',
            'hinton, geoffrey',
            'hinton, g',
            'hinton, g.',
            'hinton, g.e.'
        ]
        
        for variant in hinton_variants:
            if variant in author_name_lower:
                return True
        
        # æ›´å®½æ³›çš„åŒ¹é…ï¼šåŒ…å«geoffreyå’Œhinton
        return 'geoffrey' in author_name_lower and 'hinton' in author_name_lower
    
    def get_pdf_link(self, doi):
        """
        æ ¹æ®DOIç”ŸæˆPDFæ–‡ä»¶é“¾æ¥
        
        Args:
            doi (str): è®ºæ–‡DOI
            
        Returns:
            str: PDFæ–‡ä»¶çš„ç»å¯¹è·¯å¾„é“¾æ¥
        """
        try:
            # å°†DOIè½¬æ¢ä¸ºæ–‡ä»¶åæ ¼å¼ï¼ˆä¿æŒä¸‹åˆ’çº¿æ ¼å¼ï¼‰
            pdf_filename = f"[{doi}].pdf"
            pdf_path = os.path.join(self.pdf_dir_path, pdf_filename)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if os.path.exists(pdf_path):
                # è¿”å›file://åè®®çš„ç»å¯¹è·¯å¾„
                absolute_path = os.path.abspath(pdf_path)
                return f"file://{absolute_path}"
            else:
                logger.warning(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_filename}")
                return "PDFæ–‡ä»¶æœªæ‰¾åˆ°"
                
        except Exception as e:
            logger.error(f"ç”ŸæˆPDFé“¾æ¥æ—¶å‡ºé”™: {e}")
            return "é“¾æ¥ç”Ÿæˆå¤±è´¥"
    
    def process_papers(self, hinton_papers):
        """å¤„ç†Geoffrey Hintonçš„è®ºæ–‡"""
        logger.info("å¼€å§‹å¤„ç†è®ºæ–‡æ•°æ®...")
        
        # å…ˆå¤„ç†å°‘é‡è®ºæ–‡è¿›è¡Œæµ‹è¯•
        test_papers = hinton_papers.head(5) if len(hinton_papers) > 5 else hinton_papers
        logger.info(f"æµ‹è¯•æ¨¡å¼ï¼šå¤„ç†å‰ {len(test_papers)} ç¯‡è®ºæ–‡")
        
        for index, paper in test_papers.iterrows():
            try:
                # æå–åŸºæœ¬ä¿¡æ¯
                author = paper.get('Author', '')
                title = paper.get('Title', '')
                doi = paper.get('DOI', '')
                pub_date = paper.get('Date', paper.get('Publication Year', ''))
                
                logger.info(f"å¤„ç†ç¬¬ {len(self.results)+1} ç¯‡è®ºæ–‡: {title[:50]}...")
                
                # æŸ¥è¯¢æœºæ„ä¿¡æ¯
                affiliations = self.query_openalex_by_doi(doi)
                affiliations_str = " | ".join(affiliations) if affiliations else "æœºæ„ä¿¡æ¯æœªæ‰¾åˆ°"
                
                # ç”ŸæˆPDFé“¾æ¥
                pdf_link = self.get_pdf_link(doi)
                
                # å­˜å‚¨ç»“æœ
                result = {
                    'ä½œè€…': author,
                    'æ ‡é¢˜': title,
                    'DOI': doi,
                    'æ ‡å‡†åŒ–DOI': self.normalize_doi(doi),
                    'å‘è¡¨æ—¥æœŸ': pub_date,
                    'æœºæ„': affiliations_str,
                    'PDFé“¾æ¥': pdf_link
                }
                
                self.results.append(result)
                
                # ä¸ºé¿å…é¢‘ç¹è¯·æ±‚ï¼Œæ·»åŠ å»¶è¿Ÿ
                time.sleep(2)
                
            except Exception as e:
                logger.error(f"å¤„ç†è®ºæ–‡ {index} æ—¶å‡ºé”™: {e}")
                continue
    
    def save_to_excel(self, output_file):
        """ä¿å­˜ç»“æœåˆ°Excelæ–‡ä»¶"""
        try:
            logger.info(f"æ­£åœ¨ä¿å­˜ç»“æœåˆ°Excelæ–‡ä»¶: {output_file}")
            
            if not self.results:
                logger.warning("æ²¡æœ‰ç»“æœå¯ä»¥ä¿å­˜")
                return
            
            # åˆ›å»ºDataFrame
            df_results = pd.DataFrame(self.results)
            
            # ä½¿ç”¨openpyxlå¼•æ“ä¿å­˜ï¼Œæ”¯æŒè¶…é“¾æ¥
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                df_results.to_excel(writer, sheet_name='Hintonè®ºæ–‡æœºæ„ä¿¡æ¯', index=False)
                
                # è·å–å·¥ä½œè¡¨
                worksheet = writer.sheets['Hintonè®ºæ–‡æœºæ„ä¿¡æ¯']
                
                # è°ƒæ•´åˆ—å®½
                for column in worksheet.columns:
                    max_length = 0
                    column_name = column[0].column_letter
                    
                    for cell in column:
                        try:
                            if len(str(cell.value)) > max_length:
                                max_length = len(str(cell.value))
                        except:
                            pass
                    
                    adjusted_width = min(max_length + 2, 80)
                    worksheet.column_dimensions[column_name].width = adjusted_width
                
                # æ·»åŠ è¶…é“¾æ¥åŠŸèƒ½åˆ°PDFé“¾æ¥åˆ—
                pdf_col = len(df_results.columns)  # PDFé“¾æ¥æ˜¯æœ€åä¸€åˆ—
                for row in range(2, len(self.results) + 2):  # ä»ç¬¬2è¡Œå¼€å§‹ï¼ˆè·³è¿‡æ ‡é¢˜è¡Œï¼‰
                    cell = worksheet.cell(row=row, column=pdf_col)
                    if cell.value and cell.value.startswith('file://'):
                        cell.hyperlink = cell.value
                        cell.style = "Hyperlink"
            
            logger.info(f"æˆåŠŸä¿å­˜ {len(self.results)} æ¡è®°å½•åˆ°Excelæ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"ä¿å­˜Excelæ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def run(self, output_file):
        """æ‰§è¡Œå®Œæ•´çš„æŸ¥è¯¢æµç¨‹"""
        try:
            logger.info("=== Geoffrey Hintonæœºæ„ä¿¡æ¯æŸ¥è¯¢å¼€å§‹ï¼ˆæ”¹è¿›ç‰ˆï¼‰ ===")
            
            # 1. è¯»å–CSVæ•°æ®
            df = self.read_csv_data()
            
            # 2. ç­›é€‰Geoffrey Hintonçš„è®ºæ–‡
            hinton_papers = self.filter_hinton_papers(df)
            
            # 3. å¤„ç†è®ºæ–‡æ•°æ®
            self.process_papers(hinton_papers)
            
            # 4. ä¿å­˜åˆ°Excel
            self.save_to_excel(output_file)
            
            logger.info("=== æŸ¥è¯¢å®Œæˆ ===")
            logger.info(f"å¤„ç†äº† {len(self.results)} ç¯‡è®ºæ–‡")
            logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    try:
        # æ–‡ä»¶è·¯å¾„é…ç½®
        csv_file = "data/raw/202507271930_Hinton_Papers_30_v2.csv"
        pdf_dir = "data/processed/doi_renamed_pdfs_improved"
        output_file = f"data/processed/Geoffrey_Hinton_æœºæ„ä¿¡æ¯_æ”¹è¿›ç‰ˆ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
        if not os.path.exists(csv_file):
            logger.error(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            return
        
        if not os.path.exists(pdf_dir):
            logger.error(f"PDFç›®å½•ä¸å­˜åœ¨: {pdf_dir}")
            return
        
        # åˆ›å»ºæŸ¥è¯¢å™¨å¹¶æ‰§è¡Œ
        query = HintonAffiliationsQueryImproved(csv_file, pdf_dir)
        query.run(output_file)
        
        print(f"\nâœ… å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“Š ç»“æœæ–‡ä»¶: {output_file}")
        print(f"ğŸ“‹ å¤„ç†è®ºæ–‡æ•°é‡: {len(query.results)}")
        
        # æ˜¾ç¤ºä¸€äº›æˆåŠŸæ‰¾åˆ°æœºæ„ä¿¡æ¯çš„æ ·ä¾‹
        successful_results = [r for r in query.results if "æœºæ„ä¿¡æ¯æœªæ‰¾åˆ°" not in r['æœºæ„']]
        if successful_results:
            print(f"ğŸ‰ æˆåŠŸæ‰¾åˆ°æœºæ„ä¿¡æ¯çš„è®ºæ–‡æ•°é‡: {len(successful_results)}")
            print("\nğŸ“š æ ·ä¾‹ç»“æœ:")
            for i, result in enumerate(successful_results[:3]):
                print(f"{i+1}. {result['æ ‡é¢˜'][:50]}...")
                print(f"   æœºæ„: {result['æœºæ„']}")
        
    except Exception as e:
        logger.error(f"ä¸»ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main() 